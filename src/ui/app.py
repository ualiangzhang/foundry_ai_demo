# src/ui/app.py

"""Streamlit UI for the Startup Evaluator chain.

This app takes a startup summary and returns:
    1. Three similar startup examples (from vector-store retrieval), each truncated to 100 words.
    2. A ~100-word market context generated by LLaMA-3.
    3. Four VC-style recommendations generated by LLaMA-3.

Implementation notes:
    • Only the “Evaluator” functionality is exposed.
    • Torch internals are hidden from Streamlit’s file-watcher to prevent errors.
    • `st.set_page_config()` is called before any other Streamlit commands.
"""

from __future__ import annotations

###############################################################################
# Early monkey‐patch: provide a dummy `torch.classes` module so Streamlit’s     #
# file-watcher never inspects PyTorch internals (which raises RuntimeError).   #
###############################################################################
import types
import sys
import os

_dummy_torch_classes = types.ModuleType("torch.classes")
_dummy_torch_classes.__path__ = []  # type: ignore[attr-defined]
sys.modules["torch.classes"] = _dummy_torch_classes

os.environ["STREAMLIT_WATCHDOG_IGNORE_DIRS"] = "torch"
os.environ["STREAMLIT_WATCHDOG_IGNORE_MODULES"] = "torch"

###############################################################################
# Standard imports                                                             #
###############################################################################
import logging
from pathlib import Path
from typing import Any, Dict, List

import streamlit as st

# ── FIRST Streamlit command must be `set_page_config` ────────────────────────
st.set_page_config(
    page_title="Startup Evaluator",
    layout="centered",
)

###############################################################################
# PYTHONPATH adjustment so `src.*` imports work                                #
###############################################################################
PROJECT_ROOT: Path = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.rag.chains import build_chain  # noqa: E402

###############################################################################
# Logger configuration                                                         #
###############################################################################
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)
logger = logging.getLogger(__name__)

###############################################################################
# Cache and build only the “eval” chain                                        #
###############################################################################
@st.cache_resource
def get_eval_chain() -> Any:
    """
    Build and cache the evaluation chain.

    Returns
    -------
    Any
        A callable that expects {"question": <startup summary>} and
        returns a dict with keys "docs", "context", and "result".
    """
    return build_chain(kind="eval", store="chroma")


eval_chain: Any = get_eval_chain()

###############################################################################
# Streamlit UI                                                                 #
###############################################################################
st.title("🚀 Startup Evaluator")

# ── Input area ---------------------------------------------------------------
summary: str = st.text_area(
    label="Enter your startup summary (idea)",
    height=120,
    placeholder=(
        "e.g., A VR fitness platform with real-time coaching features and personalized workout plans…"
    ),
)

# ── Evaluation button --------------------------------------------------------
if st.button("Evaluate Startup"):
    if not summary.strip():
        st.error("❗ Please enter a non-empty startup summary.")
    else:
        try:
            # Invoke the eval chain: returns a dict containing:
            #   "docs": List[str] (top-3 similar startup examples),
            #   "context": str (~100-word market context),
            #   "result": str (four VC recommendations)
            output: Dict[str, Any] = eval_chain({"question": summary})

            # ────────────────────────────────────────────────────────────────────
            # 1) Three Similar Startup Examples (truncate to 100 words each)
            # ────────────────────────────────────────────────────────────────────
            st.subheader("📄 Three Similar Startup Examples")
            retrieved: List[str] = output.get("docs", [])
            if retrieved:
                for idx, doc_text in enumerate(retrieved, start=1):
                    words: List[str] = doc_text.strip().split()
                    truncated: str = (
                        " ".join(words[:100]) + " …" if len(words) > 100 else " ".join(words)
                    )
                    with st.expander(f"Example {idx}", expanded=False):
                        st.write(truncated)
            else:
                st.info("No similar startup examples retrieved.")

            # ────────────────────────────────────────────────────────────────────
            # 2) Market Context (~100 words)
            # ────────────────────────────────────────────────────────────────────
            st.subheader("📊 Market Context (~100 words)")
            market_context: str = output.get("context", "")
            if market_context:
                st.write(market_context)
            else:
                st.info("Market context could not be generated.")

            # ────────────────────────────────────────────────────────────────────
            # 3) VC Recommendations
            # ────────────────────────────────────────────────────────────────────
            st.subheader("💡 VC Recommendations")
            recommendations: str = output.get("result", "")
            if recommendations:
                st.write(recommendations)
            else:
                st.info("No recommendations generated by the model.")

        except Exception as exc:  # noqa: BLE001
            logger.exception("Evaluator chain failed: %s", exc)
            st.error(f"Evaluation failed: {exc}")