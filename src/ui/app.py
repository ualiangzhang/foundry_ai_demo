# src/ui/app.py

"""Streamlit UI for the Startup Evaluator chain.

Features
--------
• Accepts a startup summary as input.
• Returns:
  1. Top-3 retrieved documents (each truncated to 100 words).
  2. A ~100-word market context generated by LLaMA-3.
  3. Four VC-style recommendations generated by LLaMA-3.

Implementation notes
--------------------
• Only the “Evaluator” functionality is exposed (no Pitch-deck or Generic RAG).
• Torch internals are hidden from Streamlit’s file-watcher to suppress
  `torch.classes` traceback noise.
• `st.set_page_config()` is called **before** any other Streamlit command
  (including decorators such as `@st.cache_resource`).
"""

from __future__ import annotations

###############################################################################
# Early monkey-patch: provide a dummy `torch.classes` so Streamlit’s watcher  #
# never inspects PyTorch internals (which raises RuntimeError).               #
###############################################################################
import types
import sys
import os

_dummy_torch_classes = types.ModuleType("torch.classes")
_dummy_torch_classes.__path__ = []  # type: ignore[attr-defined]
sys.modules["torch.classes"] = _dummy_torch_classes

os.environ["STREAMLIT_WATCHDOG_IGNORE_DIRS"] = "torch"
os.environ["STREAMLIT_WATCHDOG_IGNORE_MODULES"] = "torch"

###############################################################################
# Standard imports                                                             #
###############################################################################
import logging
from pathlib import Path
from typing import Any, Dict, List

import streamlit as st
from langchain.chains import RetrievalQA

# ── FIRST Streamlit command must be `set_page_config` ─────────────────────────
st.set_page_config(
    page_title="Startup Evaluator",
    layout="centered",
)

###############################################################################
# PYTHONPATH adjustment so `src.*` imports work                                #
###############################################################################
PROJECT_ROOT: Path = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.rag.chains import build_chain  # noqa: E402

###############################################################################
# Logger configuration                                                         #
###############################################################################
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)
logger = logging.getLogger(__name__)

###############################################################################
# Lazy-load and cache the evaluation chain                                     #
###############################################################################
@st.cache_resource
def get_eval_chain() -> Any:
    """
    Build and cache the evaluation chain.

    Returns
    -------
    Any
        A callable that accepts ``{"question": <startup summary>}`` and
        returns a dictionary with keys ``result``, ``context``, ``snippet``,
        and ``docs``.
    """
    return build_chain(kind="eval", store="chroma")


eval_chain: Any = get_eval_chain()

###############################################################################
# Streamlit UI                                                                 #
###############################################################################
st.title("🚀 Startup Evaluator")

# ── Input area ---------------------------------------------------------------
summary: str = st.text_area(
    label="Enter your startup summary (idea)",
    height=120,
    placeholder=(
        "e.g., A VR fitness platform with real-time coaching and "
        "personalized workout plans…"
    ),
)

# ── Evaluation button --------------------------------------------------------
if st.button("Evaluate Startup"):
    if not summary.strip():
        st.error("❗ Please enter a non-empty startup summary.")
    else:
        try:
            result: Dict[str, Any] = eval_chain({"question": summary})

            # 1) Top-3 retrieved documents (truncate to 100 words each)
            st.subheader("📄 Top-3 Retrieved Documents")
            docs: List[str] = result.get("docs", [])
            if docs:
                for idx, doc in enumerate(docs, start=1):
                    words: List[str] = doc.strip().split()
                    truncated: str = (
                        " ".join(words[:100]) + " …" if len(words) > 100 else " ".join(words)
                    )
                    st.markdown(f"**Doc {idx}:**")
                    st.code(truncated, language="text")
            else:
                st.info("No documents retrieved.")

            # 2) Market context (~100 words)
            st.subheader("📊 Market Context")
            context: str = result.get("context", "")
            st.write(context if context else "_No context generated._")

            # 3) VC recommendations
            st.subheader("💡 VC Recommendations")
            recommendations: str = result.get("result", "")
            st.write(recommendations if recommendations else "_No recommendations generated._")

        except Exception as exc:  # noqa: BLE001
            logger.exception("Evaluator chain failed: %s", exc)
            st.error(f"Evaluation failed: {exc}")
