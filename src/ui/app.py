# src/ui/app.py

"""Streamlit UI for the Startup Evaluator chain.

This app allows a user to input a startup summary and returns:
    1. Top-3 retrieved documents (each truncated to 100 words).
    2. A ~100-word market context generated by LLaMA-3.
    3. Four VC-style recommendations generated by LLaMA-3.

Note:
    - Only the “Evaluator” functionality is exposed (no Pitch-deck or Generic RAG).
    - Torch internals are hidden from Streamlit’s file-watcher to prevent errors.
"""

from __future__ import annotations

###############################################################################
# Early monkey‐patch: provide a dummy torch.classes module so Streamlit’s     #
# file-watcher never inspects PyTorch internals and raises exceptions.        #
###############################################################################
import types
import sys
import os

# Create a dummy torch.classes module with an empty __path__ so that
# Streamlit’s watcher never attempts to read torch.classes._path
_dummy_torch_classes = types.ModuleType("torch.classes")
_dummy_torch_classes.__path__ = []  # type: ignore[attr-defined]
sys.modules["torch.classes"] = _dummy_torch_classes

# Instruct Streamlit’s watchdog to ignore any modules or directories named "torch"
os.environ["STREAMLIT_WATCHDOG_IGNORE_DIRS"] = "torch"
os.environ["STREAMLIT_WATCHDOG_IGNORE_MODULES"] = "torch"

###############################################################################
# Standard imports                                                             #
###############################################################################
import logging
from pathlib import Path
from typing import Any, Dict, List

import streamlit as st
from langchain.chains import RetrievalQA
from langchain_community.llms import HuggingFacePipeline

# ── Ensure project root is on PYTHONPATH so that `src` modules can be imported ──
# If this file is at <project_root>/src/ui/app.py, then:
#   Path(__file__).parent           -> <project_root>/src/ui
#   Path(__file__).parent.parent    -> <project_root>/src
#   Path(__file__).parent.parent.parent -> <project_root>
PROJECT_ROOT: Path = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.rag.chains import build_chain  # noqa: E402

###############################################################################
# Logger configuration                                                         #
###############################################################################
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)
logger = logging.getLogger(__name__)

###############################################################################
# Cache and build only the “eval” chain                                        #
###############################################################################
@st.cache_resource
def get_eval_chain() -> Any:
    """
    Build and cache the evaluation chain.

    Returns:
        The callable for `kind="eval"` which expects {"question": summary}.
    """
    return build_chain(kind="eval", store="chroma")


eval_chain: Any = get_eval_chain()

###############################################################################
# Streamlit UI – Single “Evaluator” Tab                                         #
###############################################################################
st.set_page_config(
    page_title="Startup Evaluator",
    layout="centered",
)

# Main title
st.title("🚀 Startup Evaluator")

# Input: Startup summary text area
summary: str = st.text_area(
    label="Enter your startup summary (idea)",
    height=120,
    placeholder="e.g., A VR fitness platform with real‐time coaching and personalized workout plans...",
)

# When user clicks “Evaluate”
if st.button("Evaluate Startup"):
    if not summary.strip():
        st.error("❗ Please enter a non-empty startup summary.")
    else:
        try:
            # Invoke the eval chain, which returns a dict containing keys:
            #   "result": str (four recommendations),
            #   "context": str (~100-word market context),
            #   "snippet": str (50-word numeric snippet),
            #   "docs": List[str] (top-3 retrieved document texts)
            output: Dict[str, Any] = eval_chain({"question": summary})

            # ────────────────────────────────────────────────────────────────────
            # 1) Display Top-3 Retrieved Documents (truncate each to 100 words)
            # ────────────────────────────────────────────────────────────────────
            st.subheader("📄 Top-3 Retrieved Documents")
            retrieved_docs: List[str] = output.get("docs", [])
            if retrieved_docs:
                for idx, doc_text in enumerate(retrieved_docs, start=1):
                    # Truncate to 100 words
                    words: List[str] = doc_text.strip().split()
                    if len(words) > 100:
                        truncated: str = " ".join(words[:100]) + " …"
                    else:
                        truncated = " ".join(words)
                    # Show in a gray box
                    st.markdown(f"**Doc {idx}:**")
                    st.code(truncated, language="text")
            else:
                st.info("No documents retrieved for this summary.")

            # ────────────────────────────────────────────────────────────────────
            # 2) Display Market Context (~100 words)
            # ────────────────────────────────────────────────────────────────────
            st.subheader("📊 Market Context (approx. 100 words)")
            market_context: str = output.get("context", "")
            if market_context:
                st.write(market_context)
            else:
                st.info("Market context could not be generated.")

            # ────────────────────────────────────────────────────────────────────
            # 3) Display Four VC Recommendations
            # ────────────────────────────────────────────────────────────────────
            st.subheader("💡 VC Recommendations")
            recommendations: str = output.get("result", "")
            if recommendations:
                st.write(recommendations)
            else:
                st.info("No recommendations generated by the model.")

        except Exception as exc:  # noqa: BLE001
            logger.exception("Evaluator chain failed: %s", exc)
            st.error(f"Evaluation failed: {exc}")
