############################################################
# LLaMA-Factory config – 2 × H100 (80 GB each)
# Small, high-quality SFT set → conservative LoRA
############################################################

### ───────── Model Settings ─────────
model_name_or_path: ./models/base/Meta-Llama-3-8B-Instruct
trust_remote_code: true

### ───────── Method Settings ────────
stage: sft
do_train: true
finetuning_type: lora
lora_rank: 16          # smaller rank = less over-fitting on 28 lines
lora_alpha: 32
lora_dropout: 0.05
lora_target: all
flash_attn: auto       # H100 has native Flash-Attention

### ───────── Dataset Settings ───────
dataset_dir: ./data_processed
dataset: sft_train
template: llama3
cutoff_len: 2048
val_size: 0.1
overwrite_cache: true
preprocessing_num_workers: 8
dataloader_num_workers: 4
max_samples: 1000      # harmless upper bound

### ───────── Output Settings ────────
output_dir: ./models/adapters/llama3_lora
logging_steps: 10
save_steps: 200
plot_loss: true
overwrite_output_dir: true
save_only_model: false
report_to: none

### ───────── Training Settings ──────
per_device_train_batch_size: 8
gradient_accumulation_steps: 4      # effective batch   = 32
learning_rate: 0.0001
weight_decay: 0.01
num_train_epochs: 3
lr_scheduler_type: cosine
warmup_ratio: 0.1
bf16: true
ddp_find_unused_parameters: false
ddp_timeout: 180000

### ───────── Evaluation Settings ────
eval_strategy: steps
eval_steps: 200
per_device_eval_batch_size: 4