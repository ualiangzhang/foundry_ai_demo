### ───────── Model Settings ─────────
model_name_or_path: ./models/base/Meta-Llama-3-8B-Instruct
trust_remote_code: true

### ───────── Method Settings ───────
stage: sft
do_train: true
finetuning_type: lora
lora_rank: 128                 # Increased to 128 now that we have 80 GB per GPU.
lora_target: all
flash_attn: auto               # Use FlashAttention on H100 if available.

### ───────── Dataset Settings ──────
dataset_dir: ./data_processed
dataset: sft_train              # Matches key in data_processed/dataset_info.json
template: llama3
cutoff_len: 2048
val_size: 0.1                   # 10% of 25 examples for quick validation (≈2–3 samples)
overwrite_cache: true
preprocessing_num_workers: 8
dataloader_num_workers: 4
max_samples: 1000               # Not reached since only 25 rows exist.

### ───────── Output Settings ───────
output_dir: ./models/adapters/llama3_lora
logging_steps: 10
save_steps: 200
plot_loss: true
overwrite_output_dir: true
save_only_model: false
report_to: none                 # No external logging service.

### ───────── Training Settings ─────
# With 80 GB per GPU, we can push batch sizes higher:
per_device_train_batch_size: 16  # Each GPU handles 16 examples → total 32 per step
gradient_accumulation_steps: 2   # Effective global batch = 32 × 2 = 64
learning_rate: 0.0002
num_train_epochs: 5.0            # More epochs to fully leverage small dataset
lr_scheduler_type: cosine
warmup_ratio: 0.1
bf16: true                       # H100 supports bfloat16 natively
ddp_find_unused_parameters: false
ddp_timeout: 180000

### ───────── Evaluation Settings ───
eval_strategy: steps
eval_steps: 200
per_device_eval_batch_size: 4     # Each GPU evals 4 examples at once
